import gradio as gr
import asyncio
import logging
from pathlib import Path

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    from src.agent import safe_run_agent_streaming, safe_run_agent, clear_memory
    from src.data_loaders import process_uploaded_file
    from src.utils import initialize_knowledge_base
except ImportError as e:
    logger.error(f"Failed to import required modules: {e}")
    raise

# Initialize knowledge base on startup
logger.info("Initializing knowledge base...")
try:
    knowledge_base = initialize_knowledge_base()
    if knowledge_base:
        logger.info("Knowledge base initialized successfully")
    else:
        logger.warning("Knowledge base initialization failed - some features may be limited")
except Exception as e:
    logger.error(f"Knowledge base initialization error: {e}")
    knowledge_base = None

# Global variable to store processed document context
processed_docs = []

async def chat_function_streaming(message: str, history: list):
    """Process user message through the agent with streaming and better error handling"""
    if not message or not message.strip():
        history.append([message, "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ„Ù‚Ù Ø£ÙŠ Ø³Ø¤Ø§Ù„. ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø³Ø¤Ø§Ù„Ùƒ Ø£Ùˆ Ø·Ù„Ø¨Ùƒ."])
        yield history, ""
        return
    
    # Add user message to history with empty response
    history.append([message, ""])
    
    try:
        # Prepare message with document context if available
        message_to_agent = message
        if processed_docs:
            str_processed_docs = "\n".join([
                f"{doc.page_content}\n{doc.metadata}" 
                for doc in processed_docs
            ])
            message_to_agent = f"{message}\n\nThis is Information you can use:\n\n{str_processed_docs}"
        
        # Stream the response
        accumulated_response = ""
        async for chunk in safe_run_agent_streaming(message_to_agent):
            accumulated_response += chunk
            history[-1][1] = accumulated_response
            yield history, ""
            
    except Exception as e:
        logger.error(f"Error in chat_function_streaming: {e}")
        history[-1][1] = f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}"
        yield history, ""

def upload_and_process_file(file) -> str:
    """Process uploaded file and add to knowledge base"""
    global processed_docs
    
    if file is None:
        return "Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ø£ÙŠ Ù…Ù„Ù"
    
    try:
        # Gradio's file object has a .name attribute which is the path to the temporary file
        file_path = Path(file)  # file is already a path string in newer versions
        
        # Validate file type
        allowed_extensions = {'.pdf', '.txt', '.docx', '.doc'}
        if file_path.suffix.lower() not in allowed_extensions:
            return f"Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: {file_path.suffix}. Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©: {', '.join(allowed_extensions)}"
        
        # Check file size (limit to 10MB)
        file_size = file_path.stat().st_size
        if file_size > 10 * 1024 * 1024:  # 10MB
            return "Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹. Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ 10 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª."
        
        # Process the uploaded file
        new_documents = process_uploaded_file(file_path)
        
        if new_documents:
            # Extend the global processed_docs list with the new documents
            processed_docs.extend(new_documents)
            return f"ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù '{file_path.name}' Ø¨Ù†Ø¬Ø§Ø­. ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© {len(new_documents)} ÙˆØ«ÙŠÙ‚Ø©."
        else:
            return f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù '{file_path.name}'"
        
    except Exception as e:
        logger.error(f"Error processing file {file}: {e}")
        return f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù '{file}': {str(e)}"

def clear_chat_memory_and_history():
    """Clear the conversation memory, processed documents, chat history, and upload status"""
    global processed_docs
    
    try:
        clear_memory()
        processed_docs = []
        logger.info("Successfully cleared chat memory and history")
        # Return empty chat history, clear status, and empty upload status
        return [], "ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¨Ù†Ø¬Ø§Ø­. Ø¨Ø¯Ø£Øª Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©!", ""
    except Exception as e:
        logger.error(f"Error clearing memory: {e}")
        return [], f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {str(e)}", ""

def validate_startup():
    """Validate system before launching"""
    required_env_vars = ["OPENAI_API_KEY"]
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        error_msg = f"Missing required environment variables: {', '.join(missing_vars)}"
        logger.error(error_msg)
        raise ValueError(error_msg)
    
    logger.info("Startup validation passed")

# Wrapper function to handle async streaming for Gradio
def chat_function_wrapper(message, history):
    """Wrapper to run the async streaming function"""
    try:
        # Create new event loop for this thread
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            # Run the async generator
            async_gen = chat_function_streaming(message, history)
            
            # Iterate through the async generator
            while True:
                try:
                    result = loop.run_until_complete(async_gen.__anext__())
                    yield result
                except StopAsyncIteration:
                    break
                    
        finally:
            loop.close()
            
    except Exception as e:
        # Fallback to non-streaming if streaming fails
        try:
            # Check if we have processed documents
            if processed_docs:
                # Create string representation of processed documents
                str_processed_docs = "\n".join([
                    f"{doc.page_content}\n{doc.metadata}" 
                    for doc in processed_docs
                ])
                message_to_agent = f"{message}\n\nThis is Information you can use:\n\n{str_processed_docs}"
                # Pass message with document context to the agent
                response = asyncio.run(safe_run_agent(message_to_agent))
            else:
                # Process normally without document context
                response = asyncio.run(safe_run_agent(message))
            
            # Add the new conversation to history
            history.append([message, response])
            yield history, ""
        except Exception as fallback_error:
            history.append([message, f"Error: {str(fallback_error)}"])
            yield history, ""

def create_interface():
    """Create and configure the Gradio interface"""
    
    # Custom CSS for full-screen responsive layout
    custom_css = """
    @import url('https://fonts.googleapis.com/css2?family=Roboto&display=swap');

    /* Global font */
    * {
        font-family: 'Roboto', sans-serif;
    }

    /* Better RTL support for Arabic */
    .rtl {
        direction: rtl;
        text-align: right;
    }

    /* Apply Roboto font only to English content explicitly if needed */
    :lang(en) {
        font-family: 'Roboto', sans-serif;
    }

    /* Responsive design for small screens */
    @media (max-width: 768px) {
        .gradio-row {
            flex-direction: column !important;
        }
    }

    /* ğŸ‘‡ Control font size in the input Textbox */
    textarea {
        font-size: 18px !important;
    }

    /* ğŸ‘‡ Control font size in the Chatbot messages */
    .message, .message-user, .message-ai {
        font-size: 18px !important;
        line-height: 1.6;
    }

    /* ğŸ‘‡ Optional: Adjust file upload input and other text areas */
    input[type="file"], .gr-textbox, .gr-textbox textarea {
        font-size: 16px !important;
    }
    """

    
    # Create the Gradio interface with full-screen layout
    with gr.Blocks(
        title="Ø§Ù„Ø´ÙØ§Ø¡ Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù„Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ© - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø·Ø¨ÙŠ", 
        css=custom_css,
        theme=gr.themes.Soft()
    ) as interface:
        
        # Arabic Header with RTL support
        gr.Markdown(
            """
            <div style="text-align: center; direction: rtl;">
            
            # ğŸ¥ Ø§Ù„Ø´ÙØ§Ø¡ Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù„Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ© - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø·Ø¨ÙŠ
            
            ### Ø§Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ø·Ø¨ÙŠØ© Ø£Ùˆ Ø§Ø±ÙØ¹ ÙˆØ«Ø§Ø¦Ù‚ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø¹Ø¯Ø© 
            
            </div>
            """, 
            elem_classes="rtl"
        )
        
        # Full-width responsive layout
        with gr.Row():
            with gr.Column(scale=3, min_width=400):  # Increased scale for chat area
                chatbot = gr.Chatbot(
                    label="ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø·Ø¨ÙŠ",
                    height=600,  # Increased height
                    show_label=True,
                    container=True,
                    bubble_full_width=False,
                    rtl=True  # Enable RTL for Arabic support
                )
                
                with gr.Row():
                    msg = gr.Textbox(
                        label="Ø±Ø³Ø§Ù„ØªÙƒ",
                        placeholder="Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø·Ø¨ÙŠØ§Ù‹ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©...",
                        scale=4,
                        container=False,
                        rtl=True
                    )
                    submit_btn = gr.Button("Ø¥Ø±Ø³Ø§Ù„", variant="primary", scale=1)
                
                gr.Markdown(
                    """
                    <div style="text-align: center; direction: rtl; color: #666; margin-top: 10px;">
                    <em>
                    Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ø§ Ù…Ø´Ø±ÙˆØ¹ ØªØ¬Ø±ÙŠØ¨ÙŠ Ø´Ø®ØµÙŠ Ù„Ø§ØºØ±Ø§Ø¶ ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙÙ‚Ø·. 
                    <br>
                    Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø´Ø±ÙˆØ¹ Ù…Ù…Ø§Ø«Ù„ØŒ ÙŠÙ…ÙƒÙ†ÙƒÙ… Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø·ÙˆØ±: 
                    <br>
                     <a href="mailto:moazeldsoky8@gmail.com">Email</a> | <a href="https://github.com/MoazEldsouky">GitHub</a> | <a href="https://www.linkedin.com/in/moaz-eldesouky-762288251/">LinkedIn</a>
                    <br>
                     WhatsApp: +201096448317
                    <br>
                    ÙÙŠ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ØŒ Ø§ØªØµÙ„ Ø¨Ù€ 997 ÙÙˆØ±Ø§Ù‹.
                    </em>
                    </div>
                    """,
                    elem_classes="rtl"
                )
                
            with gr.Column(scale=2, min_width=300):  # Side panel
                # Document Upload Section
                gr.Markdown("### ğŸ“ Ø±ÙØ¹ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚", elem_classes="rtl")
                file_upload = gr.File(
                    label="Ø§Ø±ÙØ¹ ÙˆØ«ÙŠÙ‚Ø© Ø·Ø¨ÙŠØ©",
                    file_types=[".pdf", ".txt", ".docx", ".doc"],
                    type="filepath"
                )
                upload_status = gr.Textbox(
                    label="Ø­Ø§Ù„Ø© Ø§Ù„Ø±ÙØ¹", 
                    interactive=False,
                    max_lines=3,
                    rtl=True
                )
                
                # Memory Management Section
                gr.Markdown("### ğŸ§  Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©", elem_classes="rtl")
                clear_btn = gr.Button(
                    "ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ¨Ø¯Ø¡ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©", 
                    variant="secondary",
                    size="lg"
                )
                clear_status = gr.Textbox(
                    label="Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø­", 
                    interactive=False,
                    rtl=True
                )
                
                # About section in Arabic
                with gr.Accordion("â„¹ï¸ Ø­ÙˆÙ„ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø´ÙØ§Ø¡ Ø§Ù„Ø±Ù‚Ù…ÙŠ", open=False):
                    gr.Markdown(
                        """
                        <div style="direction: rtl; text-align: right;">
                        
                        **Ø§Ù„Ù…ÙŠØ²Ø§Øª:**
                        - Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆØ¥Ø±Ø´Ø§Ø¯Ø§Øª Ø·Ø¨ÙŠØ©
                        - Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø­Ø¬Ø² Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯
                        - Ø¯Ø¹Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚
                        - Ø¯Ø¹Ù… Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ù„ØºØ© (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©/Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©)
                        - Ù…ØªØ§Ø­ 24/7 Ù„Ø®Ø¯Ù…ØªÙƒÙ…
                        
                        **Ù…Ù‡Ù…:**
                        - Ù‡Ø°Ø§ Ù„ÙŠØ³ Ø¨Ø¯ÙŠÙ„Ø§Ù‹ Ø¹Ù† Ø§Ù„Ù…Ø´ÙˆØ±Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ù…Ù‡Ù†ÙŠØ©
                        - ÙÙŠ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ØŒ Ø§ØªØµÙ„ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¨Ù€ 997
                        - Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª Ù…ÙˆÙ„Ø¯Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆÙŠØ¬Ø¨ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡Ø§ Ù…Ø¹ Ø§Ù„Ù…Ø®ØªØµÙŠÙ† Ø§Ù„Ø·Ø¨ÙŠÙŠÙ†
                        
                        **Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„:**
                        - Ø§Ù„Ø·ÙˆØ§Ø±Ø¦: 997
                        - Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡: Ù…ØªÙˆÙØ±Ø© Ø¹Ù„Ù‰ Ù…Ø¯Ø§Ø± Ø§Ù„Ø³Ø§Ø¹Ø©
                        - Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ: www.alshifadigital.com
                        - Ø§Ù„Ù‡Ø§ØªÙ: 9200-000-000 (Ù…ØªÙˆÙØ± Ø®Ù„Ø§Ù„ Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø±Ø³Ù…ÙŠØ©)
                        
                        </div>
                        """,
                        elem_classes="rtl"
                    )
        
        # Event handlers with streaming support
        def submit_message(message, history):
            """Handle message submission"""
            if message.strip():
                yield from chat_function_wrapper(message, history)
        
        # Connect the submit events
        msg.submit(
            submit_message,
            inputs=[msg, chatbot],
            outputs=[chatbot, msg]
        )
        
        submit_btn.click(
            submit_message,
            inputs=[msg, chatbot],
            outputs=[chatbot, msg]
        )
        
        # File upload handler
        file_upload.upload(
            upload_and_process_file,
            inputs=file_upload,
            outputs=upload_status
        )
        
        # Clear memory handler - now clears memory, chat history, and upload status
        clear_btn.click(
            clear_chat_memory_and_history,
            inputs=[],
            outputs=[chatbot, clear_status, upload_status]
        )
    
    return interface

def launch_gradio():
    """Launch Gradio with startup validation"""
    try:
        validate_startup()
        logger.info("Starting Gradio interface...")
        
        interface = create_interface()
        
        interface.launch(
            server_name="0.0.0.0",
            server_port=int(os.getenv("PORT", 7860)),
            share=bool(os.getenv("GRADIO_SHARE", False)),
            debug=bool(os.getenv("DEBUG", False)),
            show_error=True,
            quiet=False,
            inbrowser=True,
            favicon_path=None,
            ssl_verify=False,
            app_kwargs={}
        )
        
    except Exception as e:
        logger.error(f"Failed to launch Gradio: {e}")
        raise

if __name__ == "__main__":
    launch_gradio()